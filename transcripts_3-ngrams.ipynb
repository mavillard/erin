{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "import networkx as nx\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transcripts_df = pd.read_csv(\n",
    "    'data/out/transcripts_1.csv',\n",
    "    converters={'INTERVIEWERS': eval, 'INTERVIEWEES': eval, 'ALIASES': eval, 'INTERVIEW': eval},\n",
    ")\n",
    "transcripts_df = transcripts_df[['ID', 'INTERVIEWERS', 'INTERVIEWEES', 'ALIASES', 'INTERVIEW']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>INTERVIEWERS</th>\n",
       "      <th>INTERVIEWEES</th>\n",
       "      <th>ALIASES</th>\n",
       "      <th>INTERVIEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aimee Johnson – 17 September 2010</td>\n",
       "      <td>[Rick Fehr]</td>\n",
       "      <td>[Aimee Johnson]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(0, Rick, Ok.  We’re recording now, I’m sitti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anita Smith -</td>\n",
       "      <td>[Dave White]</td>\n",
       "      <td>[Anita Smith]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(0, Dave, How did we use to use the environme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apollo Blackeagle – 27 October 2010</td>\n",
       "      <td>[Rick Fehr, David White]</td>\n",
       "      <td>[Apollo Blackeagle]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(0, Rick, Ok, its October 27th I believe, we’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bill Sands</td>\n",
       "      <td>[Dave White]</td>\n",
       "      <td>[Bill Sands]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(0, Dave, In the past, there’s concern today ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brenda Wheat – 24 May 2011</td>\n",
       "      <td>[Rick Fehr]</td>\n",
       "      <td>[Brenda Wheat]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(0, Rick, So what we’ll be using is just a li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ID              INTERVIEWERS  \\\n",
       "0    Aimee Johnson – 17 September 2010               [Rick Fehr]   \n",
       "1                       Anita Smith -               [Dave White]   \n",
       "2  Apollo Blackeagle – 27 October 2010  [Rick Fehr, David White]   \n",
       "3                           Bill Sands              [Dave White]   \n",
       "4           Brenda Wheat – 24 May 2011               [Rick Fehr]   \n",
       "\n",
       "          INTERVIEWEES ALIASES  \\\n",
       "0      [Aimee Johnson]      []   \n",
       "1        [Anita Smith]      []   \n",
       "2  [Apollo Blackeagle]      []   \n",
       "3         [Bill Sands]      []   \n",
       "4       [Brenda Wheat]      []   \n",
       "\n",
       "                                           INTERVIEW  \n",
       "0  [(0, Rick, Ok.  We’re recording now, I’m sitti...  \n",
       "1  [(0, Dave, How did we use to use the environme...  \n",
       "2  [(0, Rick, Ok, its October 27th I believe, we’...  \n",
       "3  [(0, Dave, In the past, there’s concern today ...  \n",
       "4  [(0, Rick, So what we’ll be using is just a li...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>INTERVIEWERS</th>\n",
       "      <th>INTERVIEWEES</th>\n",
       "      <th>ALIASES</th>\n",
       "      <th>INTERVIEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aimee Johnson – 17 September 2010</td>\n",
       "      <td>[Rick Fehr]</td>\n",
       "      <td>[Aimee Johnson]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(0, Rick, Ok.  We’re recording now, I’m sitti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anita Smith -</td>\n",
       "      <td>[Dave White]</td>\n",
       "      <td>[Anita Smith]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(0, Dave, How did we use to use the environme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apollo Blackeagle – 27 October 2010</td>\n",
       "      <td>[Rick Fehr, David White]</td>\n",
       "      <td>[Apollo Blackeagle]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(0, Rick, Ok, its October 27th I believe, we’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bill Sands</td>\n",
       "      <td>[Dave White]</td>\n",
       "      <td>[Bill Sands]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(0, Dave, In the past, there’s concern today ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brenda Wheat – 24 May 2011</td>\n",
       "      <td>[Rick Fehr]</td>\n",
       "      <td>[Brenda Wheat]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(0, Rick, So what we’ll be using is just a li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ID              INTERVIEWERS  \\\n",
       "0    Aimee Johnson – 17 September 2010               [Rick Fehr]   \n",
       "1                       Anita Smith -               [Dave White]   \n",
       "2  Apollo Blackeagle – 27 October 2010  [Rick Fehr, David White]   \n",
       "3                           Bill Sands              [Dave White]   \n",
       "4           Brenda Wheat – 24 May 2011               [Rick Fehr]   \n",
       "\n",
       "          INTERVIEWEES ALIASES  \\\n",
       "0      [Aimee Johnson]      []   \n",
       "1        [Anita Smith]      []   \n",
       "2  [Apollo Blackeagle]      []   \n",
       "3         [Bill Sands]      []   \n",
       "4       [Brenda Wheat]      []   \n",
       "\n",
       "                                           INTERVIEW  \n",
       "0  [(0, Rick, Ok.  We’re recording now, I’m sitti...  \n",
       "1  [(0, Dave, How did we use to use the environme...  \n",
       "2  [(0, Rick, Ok, its October 27th I believe, we’...  \n",
       "3  [(0, Dave, In the past, there’s concern today ...  \n",
       "4  [(0, Rick, So what we’ll be using is just a li...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/out/counter_all.pickle', 'rb') as f:\n",
    "    counter_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/out/counter_adjs.pickle', 'rb') as f:\n",
    "    counter_adjs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/out/counter_nouns.pickle', 'rb') as f:\n",
    "    counter_nouns = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/out/counter_verbs.pickle', 'rb') as f:\n",
    "    counter_verbs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_ngrams(tokens, rg):\n",
    "    ngrms = []\n",
    "    for i in range(rg[0], rg[1] + 1):\n",
    "        ngrms_aux = [ngrm for ngrm in ngrams(tokens, i)]\n",
    "        ngrms.extend(ngrms_aux)\n",
    "    return ngrms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text = '\\n'.join([text for interview in transcripts_df.INTERVIEW for (index, name, text) in interview])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/out/all_text.txt') as f:\n",
    "    all_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('…', '...')\n",
    "    tokens = word_tokenize(text)\n",
    "    words = [token for token in tokens if token not in punctuation]\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.32 s, sys: 16 ms, total: 4.34 s\n",
      "Wall time: 4.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cleaned_all_text = clean_text(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = cleaned_all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrams = my_ngrams(all_words, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigrams = my_ngrams(all_words, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_adjs = counter_adjs.most_common(THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjs_blacklist = [\n",
    "    'uh…', 'yea', 'and…', 'it…', 'there…', 'the…', 'that…',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_adjs = [(w, f) for (w, f) in top_adjs if w not in adjs_blacklist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 593),\n",
       " ('little', 444),\n",
       " ('big', 428),\n",
       " ('old', 332),\n",
       " ('different', 307),\n",
       " ('much', 242),\n",
       " ('many', 229),\n",
       " ('whole', 191),\n",
       " ('right', 181),\n",
       " ('long', 176),\n",
       " ('first', 168),\n",
       " ('fish', 152),\n",
       " ('last', 139),\n",
       " ('able', 129),\n",
       " ('next', 126),\n",
       " ('certain', 125),\n",
       " ('young', 124),\n",
       " ('great', 120),\n",
       " ('indian', 118),\n",
       " ('particular', 111),\n",
       " ('wild', 101),\n",
       " ('sure', 97),\n",
       " ('real', 91),\n",
       " ('high', 90),\n",
       " ('environmental', 85),\n",
       " ('important', 83),\n",
       " ('sweet', 82),\n",
       " ('inaudible', 80),\n",
       " ('hard', 79),\n",
       " ('nice', 76),\n",
       " ('new', 76),\n",
       " ('black', 73),\n",
       " ('small', 71),\n",
       " ('white', 71),\n",
       " ('traditional', 68),\n",
       " ('bad', 66),\n",
       " ('younger', 66),\n",
       " ('open', 57),\n",
       " ('customary', 56),\n",
       " ('natural', 56),\n",
       " ('older', 55),\n",
       " ('commercial', 55),\n",
       " ('main', 54),\n",
       " ('full', 53),\n",
       " ('best', 50),\n",
       " ('better', 49),\n",
       " ('common', 49),\n",
       " ('past', 46),\n",
       " ('native', 45),\n",
       " ('invasive', 44),\n",
       " ('red', 43),\n",
       " ('public', 42),\n",
       " ('social', 41),\n",
       " ('fresh', 40),\n",
       " ('early', 40),\n",
       " ('dry', 39),\n",
       " ('late', 38),\n",
       " ('rid', 38),\n",
       " ('specific', 38),\n",
       " ('wrong', 37),\n",
       " ('outside', 36),\n",
       " ('enough', 36),\n",
       " ('huge', 36),\n",
       " ('like', 35),\n",
       " ('large', 35),\n",
       " ('least', 34),\n",
       " ('aware', 34),\n",
       " ('healthy', 33),\n",
       " ('major', 33),\n",
       " ('sustainable', 33),\n",
       " ('biggest', 31),\n",
       " ('hot', 31),\n",
       " ('clean', 31),\n",
       " ('ready', 29),\n",
       " ('live', 28),\n",
       " ('geese', 28),\n",
       " ('general', 28),\n",
       " ('alive', 28),\n",
       " ('less', 27),\n",
       " ('residential', 27),\n",
       " ('available', 27),\n",
       " ('low', 27),\n",
       " ('green', 26),\n",
       " ('non-native', 26),\n",
       " ('smaller', 25),\n",
       " ('human', 25),\n",
       " ('similar', 25),\n",
       " ('easy', 25),\n",
       " ('plentiful', 24),\n",
       " ('local', 24),\n",
       " ('deep', 24),\n",
       " ('top', 23),\n",
       " ('lower', 23)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_adjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs_bigrams_dict = defaultdict(list)\n",
    "for w, f in top_adjs:\n",
    "    for ng in bigrams:\n",
    "        if w in ng:\n",
    "            adjs_bigrams_dict[w].append(ng)\n",
    "\n",
    "adjs_bigrams_dict = dict(adjs_bigrams_dict)\n",
    "for k in adjs_bigrams_dict:\n",
    "    adjs_bigrams_dict[k] = [(ng, f) for (ng, f) in Counter(adjs_bigrams_dict[k]).most_common() if f > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjs_trigrams_dict = defaultdict(list)\n",
    "for w, f in top_adjs:\n",
    "    for ng in trigrams:\n",
    "        if w in ng:\n",
    "            adjs_trigrams_dict[w].append(ng)\n",
    "\n",
    "adjs_trigrams_dict = dict(adjs_trigrams_dict)\n",
    "for k in adjs_trigrams_dict:\n",
    "    adjs_trigrams_dict[k] = [(ng, f) for (ng, f) in Counter(adjs_trigrams_dict[k]).most_common() if f > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_nouns = counter_nouns.most_common(THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nouns_blacklist = [\n",
    "    'yea', 'hmm', 'something', 'thing', 'well', 'anything', 'everything', 'did', 'somebody', 'yeah', 'yea…',\n",
    "    'bit', 'huh', 'one', 'nothing', 'yep', 'someone',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_nouns = [(w, f) for (w, f) in top_nouns if w not in nouns_blacklist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people', 1358),\n",
       " ('time', 1088),\n",
       " ('things', 985),\n",
       " ('way', 870),\n",
       " ('lot', 857),\n",
       " ('water', 496),\n",
       " ('community', 461),\n",
       " ('stuff', 458),\n",
       " ('kind', 439),\n",
       " ('years', 343),\n",
       " ('bush', 320),\n",
       " ('area', 317),\n",
       " ('island', 309),\n",
       " ('dad', 305),\n",
       " ('today', 299),\n",
       " ('day', 275),\n",
       " ('everybody', 259),\n",
       " ('kids', 259),\n",
       " ('house', 258),\n",
       " ('year', 257),\n",
       " ('land', 256),\n",
       " ('family', 242),\n",
       " ('walpole', 242),\n",
       " ('home', 242),\n",
       " ('road', 241),\n",
       " ('place', 239),\n",
       " ('fish', 228),\n",
       " ('food', 226),\n",
       " ('right', 210),\n",
       " ('stories', 209),\n",
       " ('marsh', 202),\n",
       " ('part', 202),\n",
       " ('environment', 201),\n",
       " ('days', 201),\n",
       " ('name', 198),\n",
       " ('money', 195),\n",
       " ('laughs', 187),\n",
       " ('guys', 187),\n",
       " ('person', 184),\n",
       " ('river', 180),\n",
       " ('ducks', 179),\n",
       " ('wood', 172),\n",
       " ('school', 166),\n",
       " ('use', 166),\n",
       " ('hunting', 161),\n",
       " ('times', 160),\n",
       " ('areas', 159),\n",
       " ('hall', 158),\n",
       " ('deer', 151),\n",
       " ('trees', 149),\n",
       " ('fishing', 149),\n",
       " ('life', 146),\n",
       " ('guy', 146),\n",
       " ('side', 142),\n",
       " ('ways', 138),\n",
       " ('ones', 137),\n",
       " ('cause', 136),\n",
       " ('end', 130),\n",
       " ('language', 130),\n",
       " ('horses', 128),\n",
       " ('st.', 122),\n",
       " ('ice', 120),\n",
       " ('work', 119),\n",
       " ('point', 116),\n",
       " ('muskrat', 115),\n",
       " ('duck', 115),\n",
       " ('corn', 114),\n",
       " ('nobody', 114),\n",
       " ('kinds', 113),\n",
       " ('winter', 112),\n",
       " ('ground', 110),\n",
       " ('garden', 109),\n",
       " ('species', 109),\n",
       " ('rules', 108),\n",
       " ('law', 108),\n",
       " ('care', 108),\n",
       " ('mom', 106),\n",
       " ('grass', 104),\n",
       " ('muskrats', 103),\n",
       " ('lake', 102),\n",
       " ('potawatomi', 100),\n",
       " ('concerns', 99),\n",
       " ('resources', 98)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nouns_bigrams_dict = defaultdict(list)\n",
    "for w, f in top_nouns:\n",
    "    for ng in bigrams:\n",
    "        if w in ng:\n",
    "            nouns_bigrams_dict[w].append(ng)\n",
    "\n",
    "nouns_bigrams_dict = dict(nouns_bigrams_dict)\n",
    "for k in nouns_bigrams_dict:\n",
    "    nouns_bigrams_dict[k] = [(ng, f) for (ng, f) in Counter(nouns_bigrams_dict[k]).most_common() if f > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nouns_trigrams_dict = defaultdict(list)\n",
    "for w, f in top_nouns:\n",
    "    for ng in trigrams:\n",
    "        if w in ng:\n",
    "            nouns_trigrams_dict[w].append(ng)\n",
    "\n",
    "nouns_trigrams_dict = dict(nouns_trigrams_dict)\n",
    "for k in nouns_trigrams_dict:\n",
    "    nouns_trigrams_dict[k] = [(ng, f) for (ng, f) in Counter(nouns_trigrams_dict[k]).most_common() if f > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_verbs = counter_verbs.most_common(THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbs_blacklist = [\n",
    "    'get', 'got', 'done', 'getting', 'yea',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_verbs = [(w, f) for (w, f) in top_verbs if w not in verbs_blacklist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('know', 1867),\n",
       " ('used', 1307),\n",
       " ('remember', 1089),\n",
       " ('think', 992),\n",
       " ('going', 868),\n",
       " ('see', 655),\n",
       " ('say', 616),\n",
       " ('come', 552),\n",
       " ('use', 516),\n",
       " ('said', 512),\n",
       " ('went', 492),\n",
       " ('take', 468),\n",
       " ('put', 426),\n",
       " ('make', 382),\n",
       " ('want', 371),\n",
       " ('recall', 327),\n",
       " ('laughs', 289),\n",
       " ('came', 259),\n",
       " ('made', 251),\n",
       " ('told', 212),\n",
       " ('coming', 206),\n",
       " ('look', 205),\n",
       " ('guess', 197),\n",
       " ('bring', 195),\n",
       " ('need', 192),\n",
       " ('took', 190),\n",
       " ('hunting', 189),\n",
       " ('tell', 186),\n",
       " ('eat', 176),\n",
       " ('knew', 173),\n",
       " ('talking', 172),\n",
       " ('help', 169),\n",
       " ('give', 168),\n",
       " ('live', 163),\n",
       " ('call', 154),\n",
       " ('work', 152),\n",
       " ('keep', 147),\n",
       " ('lived', 143),\n",
       " ('says', 143),\n",
       " ('wanted', 140),\n",
       " ('talk', 140),\n",
       " ('thought', 138),\n",
       " ('start', 137),\n",
       " ('seen', 136),\n",
       " ('find', 129),\n",
       " ('mean', 128),\n",
       " ('goes', 127),\n",
       " ('looking', 126),\n",
       " ('gone', 126),\n",
       " ('called', 125),\n",
       " ('hunt', 125),\n",
       " ('hear', 123),\n",
       " ('happened', 122),\n",
       " ('cut', 118),\n",
       " ('taking', 114),\n",
       " ('saying', 114),\n",
       " ('comes', 112),\n",
       " ('trying', 111),\n",
       " ('started', 107),\n",
       " ('working', 106),\n",
       " ('heard', 99),\n",
       " ('believe', 98),\n",
       " ('let', 97),\n",
       " ('worked', 96),\n",
       " ('pick', 95),\n",
       " ('walk', 95),\n",
       " ('buy', 90),\n",
       " ('leave', 88),\n",
       " ('left', 87),\n",
       " ('set', 85),\n",
       " ('taught', 84),\n",
       " ('like', 83),\n",
       " ('using', 82),\n",
       " ('sell', 81),\n",
       " ('changed', 81),\n",
       " ('needed', 80),\n",
       " ('try', 80),\n",
       " ('asked', 78),\n",
       " ('mentioned', 78),\n",
       " ('brought', 76),\n",
       " ('growing', 74),\n",
       " ('saw', 73),\n",
       " ('making', 71),\n",
       " ('looked', 71),\n",
       " ('play', 70),\n",
       " ('fish', 69),\n",
       " ('gave', 68),\n",
       " ('stay', 67),\n",
       " ('seeing', 65),\n",
       " ('ask', 65),\n",
       " ('talked', 65),\n",
       " ('telling', 64),\n",
       " ('sit', 63),\n",
       " ('run', 62),\n",
       " ('seems', 61)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbs_bigrams_dict = defaultdict(list)\n",
    "for w, f in top_verbs:\n",
    "    for ng in bigrams:\n",
    "        if w in ng:\n",
    "            verbs_bigrams_dict[w].append(ng)\n",
    "\n",
    "verbs_bigrams_dict = dict(verbs_bigrams_dict)\n",
    "for k in verbs_bigrams_dict:\n",
    "    verbs_bigrams_dict[k] = [(ng, f) for (ng, f) in Counter(verbs_bigrams_dict[k]).most_common() if f > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbs_trigrams_dict = defaultdict(list)\n",
    "for w, f in top_verbs:\n",
    "    for ng in trigrams:\n",
    "        if w in ng:\n",
    "            verbs_trigrams_dict[w].append(ng)\n",
    "\n",
    "verbs_trigrams_dict = dict(verbs_trigrams_dict)\n",
    "for k in verbs_trigrams_dict:\n",
    "    verbs_trigrams_dict[k] = [(ng, f) for (ng, f) in Counter(verbs_trigrams_dict[k]).most_common() if f > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
